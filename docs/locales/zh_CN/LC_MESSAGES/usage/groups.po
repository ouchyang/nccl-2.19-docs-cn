# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the NCCL(2.19) package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: NCCL(2.19)\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-27 11:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: gpt-po v1.0.11\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.13.1\n"

#: ../../source/usage/groups.rst:5 73067dbe7a9d4520847efdd3d42e88a7
msgid "Group Calls"
msgstr "群组通话"

#: ../../source/usage/groups.rst:7 0ca0aade330c41b3867bbc7bda3eb456
msgid ""
"Group functions (ncclGroupStart/ncclGroupEnd) can be used to merge multiple calls into one. This is needed for three "
"purposes: managing multiple GPUs from one thread (to avoid deadlocks), aggregating communication operations to improve "
"performance, or merging multiple send/receive point-to-point operations (see :ref:`point-to-point` section). All three "
"usages can be combined together, with one exception : calls to :c:func:`ncclCommInitRank` cannot be merged with others."
msgstr ""
"组函数（ncclGroupStart/ncclGroupEnd）可用于将多个调用合并为一个。这对三个目的很有必要：从一个线程管理多个GPU（以避免死锁），聚合通信操作以提高性能，或合并多个发送/接收点对点操作（参见：:ref:`point-"
"to-point` 部分）。这三种用法可以结合在一起，唯一的例外是：调用 :c:func:`ncclCommInitRank` 不能与其他调用合并。"

#: ../../source/usage/groups.rst:14 c21260c04faf40a6923d99adeae79268
msgid "Management Of Multiple GPUs From One Thread"
msgstr "一个线程管理多个GPU"

#: ../../source/usage/groups.rst:16 6f01bba69273499d9acad6a42b88b00e
msgid ""
"When a single thread is managing multiple devices, group semantics must be used. This is because every NCCL call may "
"have to block, waiting for other threads/ranks to arrive, before effectively posting the NCCL operation on the given "
"stream. Hence, a simple loop on multiple devices like shown below could block on the first call waiting for the other "
"ones:"
msgstr "当单个线程管理多个设备时，必须使用组语义。这是因为每个 NCCL 调用可能需要阻塞，等待其他线程/排名到达，然后才能有效地在给定流上发布 NCCL 操作。因此，像下面展示的在多个设备上简单循环可能会在第一个调用上阻塞，等待其他调用完成："

#: ../../source/usage/groups.rst:25 5c605bf6edb2405899acc6e2e1457d79
msgid "To define that these calls are part of the same collective operation, ncclGroupStart and ncclGroupEnd should be used:"
msgstr "为了定义这些调用属于同一集体操作，应该使用 ncclGroupStart 和 ncclGroupEnd："

#: ../../source/usage/groups.rst:35 7d351ed5ace64f86ab4334a3eb69bd68
msgid "This will tell NCCL to treat all calls between ncclGroupStart and ncclGroupEnd as a single call to many devices."
msgstr "这将告诉NCCL将ncclGroupStart和ncclGroupEnd之间的所有调用视为对多个设备的单个调用。"

#: ../../source/usage/groups.rst:37 42faeff83add4a3aa3138a190c098ab3
msgid ""
"Caution: When called inside a group, stream operations (like ncclAllReduce) can return without having enqueued the "
"operation on the stream. Stream operations like cudaStreamSynchronize can therefore be called only after ncclGroupEnd "
"returns."
msgstr "警告：当在组内调用时，流操作（如ncclAllReduce）可能会在未将操作排入流中的情况下返回。因此，只能在ncclGroupEnd返回后调用流操作，如cudaStreamSynchronize。"

#: ../../source/usage/groups.rst:41 b3caae266cda46999d60be89590905e7
msgid "Group calls must also be used to create a communicator when one thread manages more than one device:"
msgstr "组呼也必须用于在一个线程管理多个设备时创建通信器："

#: ../../source/usage/groups.rst:53 bb5385143550496e9376b5c2c8243384
msgid ""
"Note: Contrary to NCCL 1.x, there is no need to set the CUDA device before every NCCL communication call within a "
"group, but it is still needed when calling ncclCommInitRank within a group."
msgstr "注意：与 NCCL 1.x 相反，在组内的每次 NCCL 通信调用之前无需设置 CUDA 设备，但在组内调用 ncclCommInitRank 时仍然需要设置 CUDA 设备。"

#: ../../source/usage/groups.rst:56 ../../source/usage/groups.rst:101
#: ../../source/usage/groups.rst:141 1f498fb1ca5a4d459ed6ece321d46619
#: 64b10df03fb54d558f031a657c17d3cb dbfb90dd170849dc99e2a3f4a7f1e0f8
msgid "Related links:"
msgstr "相关链接："

#: ../../source/usage/groups.rst:58 ../../source/usage/groups.rst:103
#: cfc2f080760b4cf0b23eb760aa59ab7a f71886f5ce144b0ba0c64dc603de7d64
msgid ":c:func:`ncclGroupStart`"
msgstr ":c:func:`ncclGroupStart`"

#: ../../source/usage/groups.rst:59 ../../source/usage/groups.rst:104
#: 36ca7234d97744a3a947e4626dd3745b 6974ee656c2a4fedab314227d8e807c2
msgid ":c:func:`ncclGroupEnd`"
msgstr ":c:func:`ncclGroupEnd`"

#: ../../source/usage/groups.rst:62 443ae0be2cec43b6b38ee8fc8b1dca2f
msgid "Aggregated Operations (2.2 and later)"
msgstr "聚合操作（2.2及更高版本）"

#: ../../source/usage/groups.rst:64 910eaa4962524237ad185a5d55d53540
msgid ""
"The group semantics can also be used to have multiple collective operations performed within a single NCCL launch. This "
"is useful for reducing the launch overhead, in other words, latency, as it only occurs once for multiple operations. "
"Init functions cannot be aggregated with other init functions, nor with communication functions."
msgstr "组语义也可用于在单个 NCCL 启动中执行多个集体操作。这对于减少启动开销，换句话说，延迟很有用，因为它仅对多个操作发生一次。初始化函数不能与其他初始化函数或通信函数聚合。"

#: ../../source/usage/groups.rst:68 d10e96af8bfc4ff18594a6e1fecc65d8
msgid ""
"Aggregation of collective operations can be done simply by having multiple calls to NCCL within a ncclGroupStart / "
"ncclGroupEnd section."
msgstr "集体操作的聚合可以通过在`ncclGroupStart` / `ncclGroupEnd`部分内多次调用NCCL来简单完成。"

#: ../../source/usage/groups.rst:71 591dce43f04e47e68b13d3680fa2533e
msgid "In the following example, we launch one broadcast and two allReduce operations together as a single NCCL launch."
msgstr "在下面的示例中，我们将一个广播操作和两个allReduce操作一起作为单个NCCL启动。"

#: ../../source/usage/groups.rst:81 895b130a16b0425baeddbcbec5357005
msgid ""
"It is permitted to combine aggregation with multi-GPU launch and use different communicators in a group launch as shown "
"in the Management Of Multiple GPUs From One Thread topic.  When combining multi-GPU launch and aggregation, "
"ncclGroupStart and ncclGroupEnd can be either used once or at each level. The following example groups the allReduce "
"operations from different layers and on multiple CUDA devices :"
msgstr ""
"在“一个线程管理多个 GPU”主题中，允许将聚合与多 GPU 启动结合使用，并在组启动中使用不同的通信器。在结合多 GPU 启动和聚合时，ncclGroupStart 和 ncclGroupEnd "
"可以在每个级别使用一次或多次。以下示例将来自不同层次和多个 CUDA 设备的 allReduce 操作分组："

#: ../../source/usage/groups.rst:98 76c9549e9c9b4969bf70f99b5c37cdd6
msgid ""
"Note: The NCCL operation will only be started as a whole during the last call to ncclGroupEnd. The ncclGroupStart and "
"ncclGroupEnd calls within the for loop are not necessary and do nothing."
msgstr "注意：NCCL 操作只会在最后一次调用 ncclGroupEnd 时作为一个整体启动。for 循环内的 ncclGroupStart 和 ncclGroupEnd 调用是不必要的，也不会产生任何效果。"

#: ../../source/usage/groups.rst:107 56365c8f85154877892324ce37887d2e
msgid "Nonblocking Group Operation"
msgstr "非阻塞式群组操作"

#: ../../source/usage/groups.rst:109 85c95fda2a0243d08fe1336a7a4cf261
msgid ""
"If a communicator is marked as nonblocking through ncclCommInitRankConfig, the group functions become asynchronous "
"correspondingly. In this case, if users issue multiple NCCL operations in one group, returning from ncclGroupEnd() "
"might not mean the NCCL communication kernels have been issued to CUDA streams. If ncclGroupEnd() returns ncclSuccess, "
"it means NCCL kernels have been issued to streams; if it returns ncclInProgress, it means NCCL kernels are being issued "
"to streams in the background. It is users' responsibility to make sure the state of the communicator changes into "
"ncclSuccess before calling related CUDA calls (e.g. cudaStreamSynchronize):"
msgstr ""
"如果通过ncclCommInitRankConfig将通信器标记为非阻塞，则相应地组函数变为异步。在这种情况下，如果用户在一个组中发出多个NCCL操作，在ncclGroupEnd()"
"返回之时，不代表NCCL通信内核已经发出到CUDA流中。如果ncclGroupEnd()"
"返回ncclSuccess，则表示NCCL内核已经发出到流中；如果返回ncclInProgress，则表示NCCL内核正在后台发出到流中。用户有责任确保通信器的状态在调用相关CUDA调用（例如cudaStreamSynchronize）之前"
"变为ncclSuccess："

#: ../../source/usage/groups.rst:143 39299f4f0ace49398ec0badc45415961
msgid ":c:func:`ncclCommInitRankConfig`"
msgstr ":c:func:`ncclCommInitRankConfig`"

#: ../../source/usage/groups.rst:144 bbff8c419ddb4e1491e4c55a60939ce8
msgid ":c:func:`ncclCommGetAsyncError`"
msgstr ":c:func:`ncclCommGetAsyncError`"
