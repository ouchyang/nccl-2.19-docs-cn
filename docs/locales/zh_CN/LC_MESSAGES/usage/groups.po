# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the NCCL(2.19) package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: NCCL(2.19)\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-08-27 10:46+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: gpt-po v1.0.11\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.13.1\n"

#: ../../source/usage/groups.rst:5 0b1232fa4c804392bfb170d00565b3c3
msgid "Group Calls"
msgstr "群组通话"

#: ../../source/usage/groups.rst:7 34d1f789d4ff443ba1237bfc62d6c39d
msgid ""
"Group functions (ncclGroupStart/ncclGroupEnd) can be used to merge multiple calls into one. This is needed for three "
"purposes: managing multiple GPUs from one thread (to avoid deadlocks), aggregating communication operations to improve "
"performance, or merging multiple send/receive point-to-point operations (see :ref:`point-to-point` section). All three "
"usages can be combined together, with one exception : calls to :c:func:`ncclCommInitRank` cannot be merged with others."
msgstr ""
"组函数（ncclGroupStart/ncclGroupEnd）可用于将多个调用合并为一个。这对三个目的很有必要：从一个线程管理多个GPU（以避免死锁），聚合通信操作以提高性能，或合并多个发送/接收点对点操作（参见：:ref:`point-"
"to-point` 部分）。这三种用法可以结合在一起，唯一的例外是：调用 :c:func:`ncclCommInitRank` 不能与其他调用合并。"

#: ../../source/usage/groups.rst:14 7fa66aaaadc6425491e1d77179225299
msgid "Management Of Multiple GPUs From One Thread"
msgstr "管理多个GPU从一个线程"

#: ../../source/usage/groups.rst:16 50024dda126848e6970a7cd1cc365c7c
msgid ""
"When a single thread is managing multiple devices, group semantics must be used. This is because every NCCL call may "
"have to block, waiting for other threads/ranks to arrive, before effectively posting the NCCL operation on the given "
"stream. Hence, a simple loop on multiple devices like shown below could block on the first call waiting for the other "
"ones:"
msgstr "当单个线程管理多个设备时，必须使用组语义。这是因为每个 NCCL 调用可能需要阻塞，等待其他线程/秩到达，然后才能有效地在给定流上发布 NCCL 操作。因此，像下面显示的在多个设备上的简单循环可能会在第一个调用上阻塞，等待其他调用完成："

#: ../../source/usage/groups.rst:25 167707e3688c4d669384964fd8dbb001
msgid "To define that these calls are part of the same collective operation, ncclGroupStart and ncclGroupEnd should be used:"
msgstr "为了定义这些调用属于同一集体操作，应该使用 ncclGroupStart 和 ncclGroupEnd："

#: ../../source/usage/groups.rst:35 2b28808b8f8b454ca6d8e09cf1603928
msgid "This will tell NCCL to treat all calls between ncclGroupStart and ncclGroupEnd as a single call to many devices."
msgstr "这将告诉NCCL将ncclGroupStart和ncclGroupEnd之间的所有调用视为对多个设备的单个调用。"

#: ../../source/usage/groups.rst:37 a203aca22b7b4ae382c189fc0656ae54
msgid ""
"Caution: When called inside a group, stream operations (like ncclAllReduce) can return without having enqueued the "
"operation on the stream. Stream operations like cudaStreamSynchronize can therefore be called only after ncclGroupEnd "
"returns."
msgstr "警告：当在组内调用时，流操作（如ncclAllReduce）可能会在没有将操作排入流中的情况下返回。因此，只能在ncclGroupEnd返回后调用流操作，如cudaStreamSynchronize。"

#: ../../source/usage/groups.rst:41 b9bb309b7b7e4464b4926fa7e6e2b87d
msgid "Group calls must also be used to create a communicator when one thread manages more than one device:"
msgstr "组呼也必须用于在一个线程管理多个设备时创建通信器："

#: ../../source/usage/groups.rst:53 57d83a2a67ae429f8451ff427afff552
msgid ""
"Note: Contrary to NCCL 1.x, there is no need to set the CUDA device before every NCCL communication call within a "
"group, but it is still needed when calling ncclCommInitRank within a group."
msgstr "注意：与 NCCL 1.x 相反，在组内的每次 NCCL 通信调用之前无需设置 CUDA 设备，但在组内调用 ncclCommInitRank 时仍然需要设置 CUDA 设备。"

#: ../../source/usage/groups.rst:56 ../../source/usage/groups.rst:101
#: ../../source/usage/groups.rst:141 1550a8576110488ebabf4414d5c941fe
#: 923c6020ad9b42cd97c51bea9bebfddc 9c6c4c3dc5be43a88eb71b45ba496b72
msgid "Related links:"
msgstr "相关链接："

#: ../../source/usage/groups.rst:58 ../../source/usage/groups.rst:103
#: 401c89de9f8c4f35ba549942969b44b6 aed721f91d434f15ba53b0b9ef73d534
msgid ":c:func:`ncclGroupStart`"
msgstr ":c:func:`ncclGroupStart`"

#: ../../source/usage/groups.rst:59 ../../source/usage/groups.rst:104
#: 01cac7fb512a4a47b4f9806a58f061f1 cba971157b8d434db0663c3c3cb59dad
msgid ":c:func:`ncclGroupEnd`"
msgstr ":c:func:`ncclGroupEnd`"

#: ../../source/usage/groups.rst:62 0302dcf3aa044750910398c64f939853
msgid "Aggregated Operations (2.2 and later)"
msgstr "聚合操作（2.2及更高版本）"

#: ../../source/usage/groups.rst:64 5038f5fd62504faa979f869f3ba219d1
msgid ""
"The group semantics can also be used to have multiple collective operations performed within a single NCCL launch. This "
"is useful for reducing the launch overhead, in other words, latency, as it only occurs once for multiple operations. "
"Init functions cannot be aggregated with other init functions, nor with communication functions."
msgstr "组语义还可用于在单个 NCCL 启动中执行多个集体操作。这对于减少启动开销，也就是延迟很有用，因为它仅对多个操作发生一次。初始化函数不能与其他初始化函数或通信函数聚合。"

#: ../../source/usage/groups.rst:68 230d144968af46769da9fba7ca4f2503
msgid ""
"Aggregation of collective operations can be done simply by having multiple calls to NCCL within a ncclGroupStart / "
"ncclGroupEnd section."
msgstr "集体操作的聚合可以通过在`ncclGroupStart` / `ncclGroupEnd`部分内多次调用NCCL来简单完成。"

#: ../../source/usage/groups.rst:71 51a24a75d81c42c9b4fe25cf7db2e5b6
msgid "In the following example, we launch one broadcast and two allReduce operations together as a single NCCL launch."
msgstr "在下面的示例中，我们将一个广播操作和两个allReduce操作一起作为单个NCCL启动。"

#: ../../source/usage/groups.rst:81 75f795e297f346bf82fe9f3dd30adb79
msgid ""
"It is permitted to combine aggregation with multi-GPU launch and use different communicators in a group launch as shown "
"in the Management Of Multiple GPUs From One Thread topic.  When combining multi-GPU launch and aggregation, "
"ncclGroupStart and ncclGroupEnd can be either used once or at each level. The following example groups the allReduce "
"operations from different layers and on multiple CUDA devices :"
msgstr ""
"在“一个线程管理多个 GPU”主题中，允许将聚合与多 GPU 启动结合使用，并在组启动中使用不同的通信器。在结合多 GPU 启动和聚合时，ncclGroupStart 和 ncclGroupEnd "
"可以在每个级别使用一次或多次。以下示例将来自不同层次和多个 CUDA 设备的 allReduce 操作分组："

#: ../../source/usage/groups.rst:98 e6fc3145201a4fa3aad9da4754a26038
msgid ""
"Note: The NCCL operation will only be started as a whole during the last call to ncclGroupEnd. The ncclGroupStart and "
"ncclGroupEnd calls within the for loop are not necessary and do nothing."
msgstr "注意：NCCL 操作只会在最后一次调用 ncclGroupEnd 时作为一个整体启动。for 循环内的 ncclGroupStart 和 ncclGroupEnd 调用是不必要的，也不会产生任何效果。"

#: ../../source/usage/groups.rst:107 fec651eb473a472c83c872499b0b9a4d
msgid "Nonblocking Group Operation"
msgstr "非阻塞组操作"

#: ../../source/usage/groups.rst:109 be531aebbe4344e79d04f1926a925388
msgid ""
"If a communicator is marked as nonblocking through ncclCommInitRankConfig, the group functions become asynchronous "
"correspondingly. In this case, if users issue multiple NCCL operations in one group, returning from ncclGroupEnd() "
"might not mean the NCCL communication kernels have been issued to CUDA streams. If ncclGroupEnd() returns ncclSuccess, "
"it means NCCL kernels have been issued to streams; if it returns ncclInProgress, it means NCCL kernels are being issued "
"to streams in the background. It is users' responsibility to make sure the state of the communicator changes into "
"ncclSuccess before calling related CUDA calls (e.g. cudaStreamSynchronize):"
msgstr ""
"如果通过ncclCommInitRankConfig将通信器标记为非阻塞，则相应地组函数变为异步。在这种情况下，如果用户在一个组中发出多个NCCL操作，从ncclGroupEnd()"
"返回可能并不意味着NCCL通信核心已经发出到CUDA流。如果ncclGroupEnd()"
"返回ncclSuccess，则表示NCCL核心已经发出到流；如果返回ncclInProgress，则表示NCCL核心正在后台发出到流。用户有责任确保通信器的状态在调用相关CUDA调用（例如cudaStreamSynchronize）之前变为"
"ncclSuccess："

#: ../../source/usage/groups.rst:143 6b06cdd5c69d44a19136804929c0ddea
msgid ":c:func:`ncclCommInitRankConfig`"
msgstr ":c:func:`ncclCommInitRankConfig`"

#: ../../source/usage/groups.rst:144 e2edb00a0609482c90108353a1349803
msgid ":c:func:`ncclCommGetAsyncError`"
msgstr ":c:func:`ncclCommGetAsyncError`"
